## Acknowledgements

This project uses the [node2vec Python package](https://github.com/eliorc/node2vec) by Elior Cohen (MIT License), which includes an implementation of the Node2Vec algorithm. The `node2vecImplementation/n2v_train.py` file demonstrates usage of the node2vec package and is based on example scripts by Elior Cohen. The Node2Vec code in Elior's package is based on the original implementation by [Aditya Grover et al.](https://github.com/aditya-grover/node2vec), also licensed under the MIT License.

This project also includes code adapted from [Pierre Daix-Moreux’s repository](https://github.com/dmpierre/LINE),  
licensed under the MIT License (Copyright © 2025 Pierre Daix-Moreux). That code implements the LINE algorithm described in: Tang, J., Qu, M., Wang, M., Zhang, M., Yan, J., & Mei, Q. (2015). LINE: Large-scale Information Network Embedding. *WWW 2015*.

## License

This project is licensed under the MIT License — see the [LICENSE](LICENSE) file for details.

## Instructions

Evaluation of 6 common node embedding methods used in Graph Representation Learning on a Node Clustering and a Node Classification task using a network generated by a Stochastic Block Model. These 6 embeddings methods are: Spectral Clustering, node2vec, LINE, GraRep, GraphSage, and Deep Graph Infomax.

It is highly recommended to use a virtual environment. As of August 2025, the code works with Python 3.11.9. See `requirements.txt` for the list of dependencies.

To run all 6 embedding methods and compare their performance, run ```python -u run_all.py -p1 _withincluster1probability_ -p2 _withincluster2probability_ -p3 _withincluster3probability_```, where ```-p1```, ```-p2```, & ```-p3``` represent the probability of nodes in the same cluster (cluster 1, 2, and 3, respectively) of the Stochastic Block Model (SBM) being connected to each other by an edge. Run this command from the repository's root directory. ```run_all.py``` runs each method on the same network, which has 100 nodes and is generated by an SBM with 3 clusters. 

If you would like to change the parameters for any of the embedding methods, you can do so in ```example_classification.ipynb``` (or ```example_clustering.ipynb``` for the Node Clustering task), or directly in ```run_all.py```. To see the full list of parameters for those methods, go to their corresponding ```config.py``` file.

Additionally, you can run ```run_all_density.py``` followed by ```plot_all_density.py``` to see how the NMI scores for each embedding method change as the density of the network changes. (An equivalent option for the Node Classification task to see how the accuracy changes as the network density changes will hopefully be added soon). The network densities are controlled by the within-cluster probabilities, which are given default values of 0.5, 0.6, 0.7, 0.8, & 0.9 in ```run_all_density.py```. If you would like to try different network densities, you can manually change the within-cluster probabilities in ```run_all_density.py```. ```plot_all_density.py``` produces a plot summarizing these results.
